电信项目：
	一、数据生产
		** 讨论数据结构
		** 生产数据
			** 随机产生通话建立的时间
			** 写出日志时，每一条日志都要flush()
	二、数据消费（保存）
	** Kafka接受Flume实时递交进来的数据
			情景：
				** 数据安全性要求高
				** 下游消费者众多
			操作：
				** 启动zookeeper
					~/modules/zookeeper-3.4.5/bin/zkServer.sh start
				** 配置kafka文件：server.properties
				** 启动3台kafka的broker服务
					~/modules/kafka_2.11-0.11.0.2/bin/kafka-server-start.sh ~/modules/kafka_2.11-0.11.0.2/config/server.properties
				** 创建主题（带有分区的）
					bin/kafka-topics.sh --zookeeper linux01:2181 --topic calllog --create --replication-factor 1 --partitions 3
				** 验证主题正确性：--list
					bin/kafka-topics.sh --zookeeper linux01:2181 --list
				** 准备配置flume
	** Flume采集实时写入到文件的数据
			情景：
				** 适用于采集文件中的数据
				** 适用于数据安全性要求不高的数据
				** 适用于下游消费者不多的情况
			操作：
				** 配置flume的job的conf(参考资料文件夹)
				** 启动flume
					bin/flume-ng agent --conf conf/ --name a1 --conf-file /home/admin/calllog/flume_job_calllog2kafka.conf
				** 打包数据生产者的jar包到linux的calllog目录下
				** 启动kafka控制台消费者用于测试
					bin/kafka-console-consumer.sh --zookeeper linux01:2181 --topic calllog --from-beginning
				** 启动生产数据的任务
					java -cp ct_producer-1.0-SNAPSHOT.jar producer.ProductLog /home/admin/calllog/calllog.csv
		
		** HBase实时保存一条一条流入的数据
			情景：
				** 适用于在线业务
				** 适用于离线业务
				** 适用于非结构化数据
				** 适用于结构化数据
	** Kafka API编写完成，成功进行了控制台数据实时展示
	** HBase API操作
	** 整个消费阶段完成，打成Jar包，运行测试：
		java -Djava.ext.dirs=/home/admin/calllog/kafka_hbase_lib/ -cp /home/admin/calllog/ct_consumer-1.0-SNAPSHOT.jar kafka.HBaseConsumer
	三、数据分析
		1、了解业务需求
		2、根据业务续期所需的数据样式，设计表结构
		3、考虑设计Reducer和Mapper
		4、封装各种Key和Value的类型
		5、完成各种Mapper和Reducer的操作
		6、组装Job
		7、自定义MysqlOutputForamt
			** 继承自OutputFormat
			** 覆写3个方法
				-- 返回一个RecordWriter
				-- 检查输出
				-- 返回一个Committer
			** 自定义RecordWriter
				-- write 
					-- 取出Reducer输出的各种数据
						通话次数统计
						通话时长统计

						该条数据的时间
						该条数据的主人
							-- 单独封装一个类，定义一个方法用于实现：将数据转化为维度id——Converter
				-- close
			** 定义Converter类（或者是实现自己定义的标准接口）
				-- LRUCache做经常访问维度id的缓存（仿照其他包中的代码编写的）
				-- JDBC操作，建立一个ThreadLocal对象来维护（不必要的操作：单例了JDBC连接器）
				-- 完善getDimensionID该方法的逻辑。
					** 查询缓存 -> 生成缓存的cacheKey（避免重复）
					** 查询LRUCache是否包含缓存键，如果包含则返回id
					** 如果不包含，查询Mysql对应的维度表。（有则返回，无则插入再返回）
					** 将新查询出来的id，缓存到LRUCache中
					** 返回id
	四、数据展示

第一天思路梳理：
生产日志 ->  Flume采集 -> Kafka采集 -> KafkaAPI的控制台展示 -> HBase（创建命名空间，创建表）
-> TableMapper -> Reducer -> Mysql(每天分析的数据，都要覆盖之前的数据) -> WebServer -> WebFont
																					-> Mobile

caller	callee	buildTime duration

最终结果：
	1、按照年，月，日，统计通话次数
	2、按照年，月，日，统计通话时长


15837312345		2017-01-01~2017-03-01


[2017-01-01,2017-02-01)
startRow  genRegionCode(15837312345, 201701, 6)_15837312345_201701
stopRow   genRegionCode(15837312345, 201702, 6)_15837312345_201702


[2017-02-01,2017-03-01]

05_19902496992_20170312154840_15542823911_1_1288


协处理器的使用：
1、编写代码extends BaseRegionObserver
2、打包.jar
3、重新创建表，将表在创建的时候，挂载该协处理器
4、表挂载协处理器的时候，会去Hbase的根目录下的lib目录下的jar包里，找到你刚才注册协处理器的类的路径


Mysql结果表，存储数据的讨论：
表设计：
主表：
contact_date 	contact			date_time		count_sum		duration_sum
1_1				1				1			10				360
				1				2			5				100
				13736312345		2017-06			3				200
附表：联系人
id		telephone		name
1		15837312345		张三
附表：时间表
id		year			month 			day
1		2017			-1				-1
2		2017			1				-1
3		2017			1				1
4		2017			1				2

mapper:
context.write(15837312345_2017, rowkey.toString())

reducer:
context.write(telephone_dateTime,  count_duration)

outputformat:

15837312345_2017, 10_360
		  1_1, 10_360
DUPLCATE key   1_1



05_19902496992_20170312154840_15542823911_1_1288

19902496992 2017 


2017-01 A 
2017-01 B
2017-01 C 

解压密码，Yoona、654456、654258依次尝试


2017-01-01
2017-01
2017-01