# 6.8课堂笔记

data多目录  尝试只重启本机的datanode   而不是向老师一一样重启namenode   

startbalancer.sh   数据均衡   在sbin中  

16：19  增加105节点   version  datanodeuuid  和102 一样，会互相跳。——data 和 log 文件夹删掉  重启，不用格式化。   core-site  中的namenode  是最为关键的

16：16  profile   环境变量的分发  并且  source 

eth0——mac地址可以删掉  

- **编译源码有什么用？  目的是啥？**    


好像是一对命令

心跳机制  对于的是所有datanode吗？

复习

文件块大小，主要和磁盘读写速率有关。

3.3.3——new 一个 byte数组，1kb     用循环拷贝128M     这个小车不是buffer 而是byte数组

关流可以用，IOUtils.closeStream

RandomAccessFile  类   里面有个方法 seek    指针，可以指定到具体的位置；类似的hdfs也有一个类似的方法   fis.seek（）   定位128    1024* 1024 * 128

packet   64Kb

图  8    ack  传输完成的确认 



图  fsimage   是namenode中寸的元数据信息进行序列化之后  形成的文件

checkpoint  有前提条件  满足其一就可以   edit100万条

几个问题点  总结一下



oiv    XML必须大写

namenode id  不是存在元数据中的    datanode 会向  namenode   提供信息，  datanode可能会挂掉，。

hdfs  dfsadmin -rollEdits   



不能执行命令  看看是不是环境变量的事情



${hadoop.tmp.dir}   在  core-site下面



晚上——任务

1.先解决oiv oev 命令不能使用的问题

2.今天代码敲一遍，然后背一遍namenode 工作机制 的图  

- **集群群起命令不加上sbin/就起不来，是什么原因？**   
  是因为我的Hadoop和jdk的环境变量没有配置 ，在/etc/profile 文件中添加上环境变量的配置，并且分发到其他虚拟机，并且还要source /etc/profile一下，才可以。

- **oiv oev 命令不可用   试试全路径**    
  原因同上

- **同桌遇到了集群中某些节点起不来的情况，原因是什么？**
  我刚配上Hadoop和jdk的环境变量之后，尝试了一下在桌面调用群起命令，和在Hadoop软件目录下调用群起命令，发现在桌面起用集群，很容易造成某些节点起不来的情况。所以以一定要在软件路径下使用。