# 6.11课堂笔记

早晨说的配置文件  是遇到了什么错误？ 
严春霞问的 debug 的时候 指定了路径 是在在哪里指定的？ 
在做FlowBean 的时候全残构造器的set方法的目的是为了什么？ 目的是mapper在封装对象的时候 直接调用这个方法就可以封装成对象。
第三章    需要自定义的  需要总结

切完之后提交   切片信息   jar包   配置文件
combiner  在  9  和  10 都可以执行

一个maptask  在一个datanode  上

选择在数据所在的节点 启动 map tsak    

## 源码解读（——进入方法内部的意思，缩进表示层级）

**FlowDriver**类——job类waitForComplication 方法（上来先确认JobState.DEFINE状态）
waitforcomplication ——job类下面的submit   
	再次判断JobState.DEFINE状态
	使用新的API
	connect（） 连接yarn 集群
	submit——connect（）
		先判断cluster是不是null， 我们没有，是null，  所以进入方法内部的initialize
			connect（）——initialize  有锁   给客户端赋值
				initialize ——create  给客户端赋值    赋的是FRAMEWORK_NAME，默认是local
				回到了Cluster类  客户端协议已经赋值了，客户端协议给了客户端，所以说localjobrunner就是客户端
			initialize方法走完了，其目的是获取了一个带有协议的客户端
		cluster方法走完了，相当于集群的对象创建好了
	connect（）方法走完了 其作用是创建了一个cluster 对象，在cluster 对象里面获得了一个客户端
	JobSubmitter
		JobSubmitter——submitJobInternal   开始提交任务了     checkspaces 检查输出路径的（进去看了一圈）
		InetAddress ip = InetAddress.getLocalHost(); 得到了本地的一个路径jobstagingArea  这个路径在idea的安装路径下我的是在这		里E:\tmp\hadoop-Y\mapred\staging\Y312542254\.staging
		获取ip 主机名  jobID
	
connect——cluster——initailize为了创建客户端的
有一堆校验
copyAndConfiguration。。。创建提交路径的文件夹   
writesplits   生成2个文件   都是切片规划的信息  （maptask 由 切片个数决定）

```
writenewsplits
获取input 实例
getsplits  返回集合  类型是inputsplits   max  min 【getsplits是filinputformat下面的方法  ——getminsplictsize——1   getmaxsplictsize——long的最大值  】
获取文件path 
获取文件大小
面试题   判断是否能被切分【获取块的大小33554432   32M  在本地默认32M  在集群 是128m;计算切片大小——可以更改 更改minsize 或者 maxsize   】

面试题   对比剩余文件bytesremaining/splitssize  的大小 是不是大于1.1  是 进入循环 执行切片 makesplits  start-0 splitsize-32 生成第一个切片  再循环  判断 放入第二个切片  
```

生成了一个数组  为了排序   
给了maps   返回给 writesplits
writeconf   写配置文件
没有提交jar包   

两次shift——搜索   ctrl + H ——继承关系
